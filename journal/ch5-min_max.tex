\chapter{Min-Max Algorithm}
The min-max algorithm is the most commonly used algorithm when implementing chess engines. As opposed to MCTS, it has the advantage of being simpler to implement, computationally faster (when optimsed) and requires less tuning. The min-max algorithm begins as an exhaustive search, exploring each and every possibility up to a certain depth and assigning scores for all of the leaves in the hypothetical tree using the evaluation function. The min-max algorithm takes the lowest score of the ``children'' for the parents to account for the worst case scenario. Then, in the highest layer, the best of the worst scores is taken as the move chosen by the engine. A minor improvement that is made to the min-max algorithm is the ``negamax'' algorithm, which uses the fact that chess is a two sided game and as advantages are calculated for the current side, the best score of the previous layer can be taken as a negative to form the worst possible score of the current layer. This allows the algorithm to become fully recursive and therefore easier to read. Unlike the MCTS algorithm, a data structure is not required to store the possible movements as each possible move or board state is only visited once. Furthermore, this algorithm is easier to implement using multithreading as there are no problems involving concurrent data structure alterations. Hence in my implementation of the min-max algorithm, I multithread the computation of the first depth of the min-max algorithm. Remembering Amdahl's Law: \[S = \frac{1}{1 - p + \frac{p}{n}}\] $p$ in our case is almost 1 due to the fact that the branching factor in chess does not vary greatly due to each branch originating from the same source and being of the same depth - there is not too great of a possibility to completely diverge. 
\section{Alpha-Beta Pruning}
The min-max algorithm is an exponential-time algorithm with a time complexity of $O(b^d)$, where $b$ is the branching factor and $d$ is the depth of search. This is as for every possible move, every possible move of each possible move must be visited in the min-max algorithm. Hence without any optimisations, a high depth of search is infeasible as chess is usually played with time control. As depth is quite important when creating a strong chess engine, this is an important problem to fix.\\\\
The most common solution to this problem is \textit{alpha-beta pruning}. This is an addition to the min-max algorithm which keeps the \textit{alpha} (representing the best value that the maximising player can currently guarantee) and the \textit{beta} (representing the best value that the minimising player can currently guarantee). This allows us to use a conditional to ``prune'' branches that are worse than the current \textit{alpha}, drastically reducing computation time. As we traverse into a lower depth, we swap and negate the \textit{alpha} and \textit{beta} values as the turn and hence perspective changes by virtue of the ``negamax'' algorithm.\\\\
What this achieves is the ``pruning'' of branches that are unrealistic because the opponent would not choose them because they are worse than the opponent's best possible choice and also branches that are worse than our best choice. Whilst the time complexity of the worst case remains the same $O(b^d)$ as if the worst moves are explored first in ascending order no branches will be pruned, the time complexities of the average and best cases become much better becoming $O(b^{\frac{3d}{4}})$ and $O(b^{\frac{d}{2}})$ respectively. 
\section{Move Ordering}
In order to ensure that the best case time complexity of the improved min-max algorithm is achieved, it is imperative that the best moves are searched first so that the worse moves can be pruned. If a bad move is searched before a better move is found, then the bad move would be fully searched without being pruned. Using the following heuristic: moves that attack pieces and moves that check pieces are more often better than `quiet' moves, chess engines often order their moves such that moves that check the king or attack another piece is moved to the front of the list. In more advanced chess engines, more advanced heuristics can be used for better move ordering, but my implementation followed the simpler approach of placing the attacking moves to the front. This required me to replace the std::vector that I was originally using with the std::deque (double ended queue) for faster at front insertions. Despite a std::list being identical in terms of time complexity, the principle of spatial locality means that the deque is faster as the C++ deque implementation is largely contiguous in memory whereas the list can be scattered throughout memory using indirection to access the next element. Hence elements in the deque are more likely to be in cache resulting in faster computations.